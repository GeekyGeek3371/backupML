{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "**Importing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M52QDmyzhh9s"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Social_Network_Ads_log_reg.csv')\n",
    "gendermap = {'Male':0,'Female':1}\n",
    "dataset['Gender']=dataset['Gender'].map(gendermap)\n",
    "dataset2 = dataset.copy()\n",
    "dataset2 = dataset.drop(['Purchased'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X = dataset2.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0doGROj0wfK"
   },
   "source": [
    "**label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGPnm9m0vT8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "P3nS3-6r1i2B",
    "outputId": "0ec7f204-fd81-4c59-8897-f1effb6d6dae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[     1     44  39000]\n [     0     32 120000]\n [     1     38  50000]\n [     1     32 135000]\n [     1     52  21000]\n [     1     53 104000]\n [     0     39  42000]\n [     0     38  61000]\n [     1     36  50000]\n [     1     36  63000]\n [     1     35  25000]\n [     0     35  50000]\n [     0     42  73000]\n [     1     47  49000]\n [     1     59  29000]\n [     0     49  65000]\n [     1     45 131000]\n [     1     31  89000]\n [     1     46  82000]\n [     1     47  51000]\n [     0     26  15000]\n [     0     60 102000]\n [     1     38 112000]\n [     0     40 107000]\n [     1     42  53000]\n [     0     35  59000]\n [     0     48  41000]\n [     1     48 134000]\n [     1     38 113000]\n [     0     29 148000]\n [     1     26  15000]\n [     0     60  42000]\n [     0     24  19000]\n [     0     42 149000]\n [     1     46  96000]\n [     0     28  59000]\n [     0     39  96000]\n [     0     28  89000]\n [     0     41  72000]\n [     0     45  26000]\n [     1     33  69000]\n [     1     20  82000]\n [     0     31  74000]\n [     0     42  80000]\n [     1     35  72000]\n [     1     33 149000]\n [     0     40  71000]\n [     1     51 146000]\n [     0     46  79000]\n [     0     35  75000]\n [     0     38  51000]\n [     1     36  75000]\n [     1     37  78000]\n [     0     38  61000]\n [     1     60 108000]\n [     1     20  82000]\n [     0     57  74000]\n [     0     42  65000]\n [     0     26  80000]\n [     0     46 117000]\n [     0     35  61000]\n [     1     21  68000]\n [     1     28  44000]\n [     0     41  87000]\n [     1     37  33000]\n [     0     27  90000]\n [     0     39  42000]\n [     0     28 123000]\n [     1     31 118000]\n [     0     25  87000]\n [     1     35  71000]\n [     0     37  70000]\n [     0     35  39000]\n [     0     47  23000]\n [     1     35 147000]\n [     1     48 138000]\n [     0     26  86000]\n [     0     25  79000]\n [     1     52 138000]\n [     0     51  23000]\n [     1     35  60000]\n [     1     33 113000]\n [     0     30 107000]\n [     0     48  33000]\n [     1     41  80000]\n [     1     48  96000]\n [     0     31  18000]\n [     1     31  71000]\n [     0     43 129000]\n [     1     59  76000]\n [     1     18  44000]\n [     0     36 118000]\n [     1     42  90000]\n [     1     47  30000]\n [     1     26  43000]\n [     0     40  78000]\n [     0     46  59000]\n [     1     59  42000]\n [     1     46  74000]\n [     0     35  91000]\n [     1     28  59000]\n [     0     40  57000]\n [     0     59 143000]\n [     1     57  26000]\n [     1     52  38000]\n [     1     47 113000]\n [     1     53 143000]\n [     0     35  27000]\n [     1     58 101000]\n [     1     45  45000]\n [     1     23  82000]\n [     0     46  23000]\n [     0     42  65000]\n [     1     28  84000]\n [     0     38  59000]\n [     1     26  84000]\n [     1     29  28000]\n [     1     37  71000]\n [     1     22  55000]\n [     1     48  35000]\n [     0     49  28000]\n [     1     38  65000]\n [     1     27  17000]\n [     0     46  28000]\n [     0     48 141000]\n [     1     26  17000]\n [     1     35  97000]\n [     1     39  59000]\n [     1     24  27000]\n [     0     32  18000]\n [     0     46  88000]\n [     0     35  58000]\n [     0     56  60000]\n [     0     47  34000]\n [     1     40  72000]\n [     0     32 100000]\n [     1     19  21000]\n [     0     25  90000]\n [     0     35  88000]\n [     0     28  32000]\n [     1     50  20000]\n [     0     40  59000]\n [     1     50  44000]\n [     0     35  72000]\n [     1     40 142000]\n [     1     46  32000]\n [     1     39  71000]\n [     0     20  74000]\n [     0     29  75000]\n [     0     31  76000]\n [     0     47  25000]\n [     0     40  61000]\n [     0     34 112000]\n [     1     38  80000]\n [     1     42  75000]\n [     1     47  47000]\n [     1     39  75000]\n [     0     19  25000]\n [     1     37  80000]\n [     0     36  60000]\n [     0     41  52000]\n [     0     36 125000]\n [     1     48  29000]\n [     1     36 126000]\n [     1     51 134000]\n [     1     27  57000]\n [     0     38  71000]\n [     1     39  61000]\n [     1     22  27000]\n [     1     33  60000]\n [     0     48  74000]\n [     1     58  23000]\n [     0     53  72000]\n [     1     32 117000]\n [     0     54  70000]\n [     0     30  80000]\n [     1     58  95000]\n [     1     26  52000]\n [     0     45  79000]\n [     0     24  55000]\n [     0     40  75000]\n [     1     33  28000]\n [     1     44 139000]\n [     0     22  18000]\n [     1     33  51000]\n [     1     43 133000]\n [     1     24  32000]\n [     1     46  22000]\n [     0     35  55000]\n [     1     54 104000]\n [     1     48 119000]\n [     0     35  53000]\n [     0     37 144000]\n [     1     23  66000]\n [     1     37 137000]\n [     0     31  58000]\n [     1     33  41000]\n [     1     45  22000]\n [     0     30  15000]\n [     0     19  19000]\n [     0     49  74000]\n [     0     39 122000]\n [     0     35  73000]\n [     0     39  71000]\n [     0     24  23000]\n [     1     41  72000]\n [     1     29  83000]\n [     1     54  26000]\n [     1     35  44000]\n [     0     37  75000]\n [     1     29  47000]\n [     1     31  68000]\n [     0     42  54000]\n [     0     30 135000]\n [     1     52 114000]\n [     1     50  36000]\n [     0     56 133000]\n [     0     29  61000]\n [     0     30  89000]\n [     0     26  16000]\n [     0     33  31000]\n [     1     41  72000]\n [     0     36  33000]\n [     1     55 125000]\n [     1     48 131000]\n [     1     41  71000]\n [     1     30  62000]\n [     0     37  72000]\n [     1     41  63000]\n [     1     58  47000]\n [     1     30 116000]\n [     0     20  49000]\n [     0     37  74000]\n [     0     41  59000]\n [     0     49  89000]\n [     0     28  79000]\n [     1     53  82000]\n [     0     40  57000]\n [     0     60  34000]\n [     0     35 108000]\n [     0     21  72000]\n [     0     38  71000]\n [     0     39 106000]\n [     1     37  57000]\n [     1     26  72000]\n [     1     35  23000]\n [     1     54 108000]\n [     0     30  17000]\n [     0     39 134000]\n [     0     29  43000]\n [     0     33  43000]\n [     0     35  38000]\n [     0     41  45000]\n [     1     41  72000]\n [     1     39 134000]\n [     1     27 137000]\n [     1     21  16000]\n [     0     26  32000]\n [     0     31  66000]\n [     1     39  73000]\n [     0     41  79000]\n [     1     47  50000]\n [     1     41  30000]\n [     1     37  93000]\n [     1     60  46000]\n [     0     25  22000]\n [     1     28  37000]\n [     1     38  55000]\n [     1     36  54000]\n [     1     20  36000]\n [     1     56 104000]\n [     0     40  57000]\n [     1     42 108000]\n [     1     20  23000]\n [     0     40  65000]\n [     0     47  20000]\n [     1     18  86000]\n [     0     35  79000]\n [     1     57  33000]\n [     1     34  72000]\n [     1     49  39000]\n [     1     27  31000]\n [     0     19  70000]\n [     1     39  79000]\n [     0     26  81000]\n [     0     25  80000]\n [     1     28  85000]\n [     0     55  39000]\n [     1     50  88000]\n [     0     49  88000]\n [     0     52 150000]\n [     1     35  65000]\n [     0     42  54000]\n [     0     34  43000]\n [     0     37  52000]\n [     1     48  30000]\n [     0     29  43000]\n [     0     36  52000]\n [     1     27  54000]\n [     1     26 118000]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8dpDLojm1mVG",
    "outputId": "9cd8ff93-a749-4372-e617-7592dd478a6f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1\n 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1\n 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0\n 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0\n 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0\n 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1\n 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "qbb7i0DH1qui",
    "outputId": "dabd2149-ff55-4beb-ac97-7848d23e03a0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[     0     30  87000]\n [     1     38  50000]\n [     0     35  75000]\n [     1     30  79000]\n [     1     35  50000]\n [     0     27  20000]\n [     1     31  15000]\n [     0     36 144000]\n [     1     18  68000]\n [     0     47  43000]\n [     0     30  49000]\n [     1     28  55000]\n [     0     37  55000]\n [     0     39  77000]\n [     0     20  86000]\n [     1     32 117000]\n [     0     37  77000]\n [     0     19  85000]\n [     1     55 130000]\n [     0     35  22000]\n [     1     35  47000]\n [     1     47 144000]\n [     1     41  51000]\n [     0     47 105000]\n [     1     23  28000]\n [     1     49 141000]\n [     1     28  87000]\n [     0     29  80000]\n [     1     37  62000]\n [     1     32  86000]\n [     0     21  88000]\n [     0     37  79000]\n [     0     57  60000]\n [     0     37  53000]\n [     0     24  58000]\n [     0     18  52000]\n [     0     22  81000]\n [     1     34  43000]\n [     1     31  34000]\n [     1     49  36000]\n [     0     27  88000]\n [     0     41  52000]\n [     1     27  84000]\n [     0     35  20000]\n [     1     43 112000]\n [     1     27  58000]\n [     1     37  80000]\n [     1     52  90000]\n [     0     26  30000]\n [     0     49  86000]\n [     1     57 122000]\n [     1     34  25000]\n [     1     35  57000]\n [     0     34 115000]\n [     1     59  88000]\n [     0     45  32000]\n [     1     29  83000]\n [     1     26  80000]\n [     0     49  28000]\n [     0     23  20000]\n [     0     32  18000]\n [     0     60  42000]\n [     0     19  76000]\n [     0     36  99000]\n [     1     19  26000]\n [     0     60  83000]\n [     1     24  89000]\n [     0     27  58000]\n [     0     40  47000]\n [     1     42  70000]\n [     1     32 150000]\n [     1     35  77000]\n [     1     22  63000]\n [     0     45  22000]\n [     0     27  89000]\n [     0     18  82000]\n [     1     42  79000]\n [     1     40  60000]\n [     1     53  34000]\n [     1     47 107000]\n [     0     58 144000]\n [     1     59  83000]\n [     1     24  55000]\n [     1     26  35000]\n [     1     58  38000]\n [     1     42  80000]\n [     1     40  75000]\n [     0     59 130000]\n [     1     46  41000]\n [     1     41  60000]\n [     0     42  64000]\n [     1     37 146000]\n [     1     23  48000]\n [     0     25  33000]\n [     0     24  84000]\n [     1     27  96000]\n [     0     23  63000]\n [     0     48  33000]\n [     0     48  90000]\n [     0     42 104000]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kj1hnFAR1s5w",
    "outputId": "d5a7df73-acee-4fa6-b84a-5cef58fa12fd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0\n 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1\n 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "syrnD1Op2BSR",
    "outputId": "572ec6e9-6c3f-4f18-f441-a9233ef85e0b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.98019606  0.58164944 -0.88670699]\n [-1.02020406 -0.60673761  1.46173768]\n [ 0.98019606 -0.01254409 -0.5677824 ]\n [ 0.98019606 -0.60673761  1.89663484]\n [ 0.98019606  1.37390747 -1.40858358]\n [ 0.98019606  1.47293972  0.99784738]\n [-1.02020406  0.08648817 -0.79972756]\n [-1.02020406 -0.01254409 -0.24885782]\n [ 0.98019606 -0.21060859 -0.5677824 ]\n [ 0.98019606 -0.21060859 -0.19087153]\n [ 0.98019606 -0.30964085 -1.29261101]\n [-1.02020406 -0.30964085 -0.5677824 ]\n [-1.02020406  0.38358493  0.09905991]\n [ 0.98019606  0.8787462  -0.59677555]\n [ 0.98019606  2.06713324 -1.17663843]\n [-1.02020406  1.07681071 -0.13288524]\n [ 0.98019606  0.68068169  1.78066227]\n [ 0.98019606 -0.70576986  0.56295021]\n [ 0.98019606  0.77971394  0.35999821]\n [ 0.98019606  0.8787462  -0.53878926]\n [-1.02020406 -1.20093113 -1.58254245]\n [-1.02020406  2.1661655   0.93986109]\n [ 0.98019606 -0.01254409  1.22979253]\n [-1.02020406  0.18552042  1.08482681]\n [ 0.98019606  0.38358493 -0.48080297]\n [-1.02020406 -0.30964085 -0.30684411]\n [-1.02020406  0.97777845 -0.8287207 ]\n [ 0.98019606  0.97777845  1.8676417 ]\n [ 0.98019606 -0.01254409  1.25878567]\n [-1.02020406 -0.90383437  2.27354572]\n [ 0.98019606 -1.20093113 -1.58254245]\n [-1.02020406  2.1661655  -0.79972756]\n [-1.02020406 -1.39899564 -1.46656987]\n [-1.02020406  0.38358493  2.30253886]\n [ 0.98019606  0.77971394  0.76590222]\n [-1.02020406 -1.00286662 -0.30684411]\n [-1.02020406  0.08648817  0.76590222]\n [-1.02020406 -1.00286662  0.56295021]\n [-1.02020406  0.28455268  0.07006676]\n [-1.02020406  0.68068169 -1.26361786]\n [ 0.98019606 -0.50770535 -0.01691267]\n [ 0.98019606 -1.79512465  0.35999821]\n [-1.02020406 -0.70576986  0.12805305]\n [-1.02020406  0.38358493  0.30201192]\n [ 0.98019606 -0.30964085  0.07006676]\n [ 0.98019606 -0.50770535  2.30253886]\n [-1.02020406  0.18552042  0.04107362]\n [ 0.98019606  1.27487521  2.21555943]\n [-1.02020406  0.77971394  0.27301877]\n [-1.02020406 -0.30964085  0.1570462 ]\n [-1.02020406 -0.01254409 -0.53878926]\n [ 0.98019606 -0.21060859  0.1570462 ]\n [ 0.98019606 -0.11157634  0.24402563]\n [-1.02020406 -0.01254409 -0.24885782]\n [ 0.98019606  2.1661655   1.11381995]\n [ 0.98019606 -1.79512465  0.35999821]\n [-1.02020406  1.86906873  0.12805305]\n [-1.02020406  0.38358493 -0.13288524]\n [-1.02020406 -1.20093113  0.30201192]\n [-1.02020406  0.77971394  1.37475825]\n [-1.02020406 -0.30964085 -0.24885782]\n [ 0.98019606 -1.6960924  -0.04590581]\n [ 0.98019606 -1.00286662 -0.74174127]\n [-1.02020406  0.28455268  0.50496393]\n [ 0.98019606 -0.11157634 -1.06066585]\n [-1.02020406 -1.10189888  0.59194336]\n [-1.02020406  0.08648817 -0.79972756]\n [-1.02020406 -1.00286662  1.54871711]\n [ 0.98019606 -0.70576986  1.40375139]\n [-1.02020406 -1.29996338  0.50496393]\n [ 0.98019606 -0.30964085  0.04107362]\n [-1.02020406 -0.11157634  0.01208048]\n [-1.02020406 -0.30964085 -0.88670699]\n [-1.02020406  0.8787462  -1.3505973 ]\n [ 0.98019606 -0.30964085  2.24455257]\n [ 0.98019606  0.97777845  1.98361427]\n [-1.02020406 -1.20093113  0.47597078]\n [-1.02020406 -1.29996338  0.27301877]\n [ 0.98019606  1.37390747  1.98361427]\n [-1.02020406  1.27487521 -1.3505973 ]\n [ 0.98019606 -0.30964085 -0.27785096]\n [ 0.98019606 -0.50770535  1.25878567]\n [-1.02020406 -0.80480212  1.08482681]\n [-1.02020406  0.97777845 -1.06066585]\n [ 0.98019606  0.28455268  0.30201192]\n [ 0.98019606  0.97777845  0.76590222]\n [-1.02020406 -0.70576986 -1.49556302]\n [ 0.98019606 -0.70576986  0.04107362]\n [-1.02020406  0.48261718  1.72267598]\n [ 0.98019606  2.06713324  0.18603934]\n [ 0.98019606 -1.99318916 -0.74174127]\n [-1.02020406 -0.21060859  1.40375139]\n [ 0.98019606  0.38358493  0.59194336]\n [ 0.98019606  0.8787462  -1.14764529]\n [ 0.98019606 -1.20093113 -0.77073441]\n [-1.02020406  0.18552042  0.24402563]\n [-1.02020406  0.77971394 -0.30684411]\n [ 0.98019606  2.06713324 -0.79972756]\n [ 0.98019606  0.77971394  0.12805305]\n [-1.02020406 -0.30964085  0.6209365 ]\n [ 0.98019606 -1.00286662 -0.30684411]\n [-1.02020406  0.18552042 -0.3648304 ]\n [-1.02020406  2.06713324  2.12857999]\n [ 0.98019606  1.86906873 -1.26361786]\n [ 0.98019606  1.37390747 -0.91570013]\n [ 0.98019606  0.8787462   1.25878567]\n [ 0.98019606  1.47293972  2.12857999]\n [-1.02020406 -0.30964085 -1.23462472]\n [ 0.98019606  1.96810099  0.91086794]\n [ 0.98019606  0.68068169 -0.71274813]\n [ 0.98019606 -1.49802789  0.35999821]\n [-1.02020406  0.77971394 -1.3505973 ]\n [-1.02020406  0.38358493 -0.13288524]\n [ 0.98019606 -1.00286662  0.41798449]\n [-1.02020406 -0.01254409 -0.30684411]\n [ 0.98019606 -1.20093113  0.41798449]\n [ 0.98019606 -0.90383437 -1.20563157]\n [ 0.98019606 -0.11157634  0.04107362]\n [ 0.98019606 -1.59706014 -0.42281668]\n [ 0.98019606  0.97777845 -1.00267957]\n [-1.02020406  1.07681071 -1.20563157]\n [ 0.98019606 -0.01254409 -0.13288524]\n [ 0.98019606 -1.10189888 -1.52455616]\n [-1.02020406  0.77971394 -1.20563157]\n [-1.02020406  0.97777845  2.07059371]\n [ 0.98019606 -1.20093113 -1.52455616]\n [ 0.98019606 -0.30964085  0.79489537]\n [ 0.98019606  0.08648817 -0.30684411]\n [ 0.98019606 -1.39899564 -1.23462472]\n [-1.02020406 -0.60673761 -1.49556302]\n [-1.02020406  0.77971394  0.53395707]\n [-1.02020406 -0.30964085 -0.33583725]\n [-1.02020406  1.77003648 -0.27785096]\n [-1.02020406  0.8787462  -1.03167271]\n [ 0.98019606  0.18552042  0.07006676]\n [-1.02020406 -0.60673761  0.8818748 ]\n [ 0.98019606 -1.89415691 -1.40858358]\n [-1.02020406 -1.29996338  0.59194336]\n [-1.02020406 -0.30964085  0.53395707]\n [-1.02020406 -1.00286662 -1.089659  ]\n [ 0.98019606  1.17584296 -1.43757673]\n [-1.02020406  0.18552042 -0.30684411]\n [ 0.98019606  1.17584296 -0.74174127]\n [-1.02020406 -0.30964085  0.07006676]\n [ 0.98019606  0.18552042  2.09958685]\n [ 0.98019606  0.77971394 -1.089659  ]\n [ 0.98019606  0.08648817  0.04107362]\n [-1.02020406 -1.79512465  0.12805305]\n [-1.02020406 -0.90383437  0.1570462 ]\n [-1.02020406 -0.70576986  0.18603934]\n [-1.02020406  0.8787462  -1.29261101]\n [-1.02020406  0.18552042 -0.24885782]\n [-1.02020406 -0.4086731   1.22979253]\n [ 0.98019606 -0.01254409  0.30201192]\n [ 0.98019606  0.38358493  0.1570462 ]\n [ 0.98019606  0.8787462  -0.65476184]\n [ 0.98019606  0.08648817  0.1570462 ]\n [-1.02020406 -1.89415691 -1.29261101]\n [ 0.98019606 -0.11157634  0.30201192]\n [-1.02020406 -0.21060859 -0.27785096]\n [-1.02020406  0.28455268 -0.50979612]\n [-1.02020406 -0.21060859  1.6067034 ]\n [ 0.98019606  0.97777845 -1.17663843]\n [ 0.98019606 -0.21060859  1.63569655]\n [ 0.98019606  1.27487521  1.8676417 ]\n [ 0.98019606 -1.10189888 -0.3648304 ]\n [-1.02020406 -0.01254409  0.04107362]\n [ 0.98019606  0.08648817 -0.24885782]\n [ 0.98019606 -1.59706014 -1.23462472]\n [ 0.98019606 -0.50770535 -0.27785096]\n [-1.02020406  0.97777845  0.12805305]\n [ 0.98019606  1.96810099 -1.3505973 ]\n [-1.02020406  1.47293972  0.07006676]\n [ 0.98019606 -0.60673761  1.37475825]\n [-1.02020406  1.57197197  0.01208048]\n [-1.02020406 -0.80480212  0.30201192]\n [ 0.98019606  1.96810099  0.73690908]\n [ 0.98019606 -1.20093113 -0.50979612]\n [-1.02020406  0.68068169  0.27301877]\n [-1.02020406 -1.39899564 -0.42281668]\n [-1.02020406  0.18552042  0.1570462 ]\n [ 0.98019606 -0.50770535 -1.20563157]\n [ 0.98019606  0.58164944  2.01260742]\n [-1.02020406 -1.59706014 -1.49556302]\n [ 0.98019606 -0.50770535 -0.53878926]\n [ 0.98019606  0.48261718  1.83864855]\n [ 0.98019606 -1.39899564 -1.089659  ]\n [ 0.98019606  0.77971394 -1.37959044]\n [-1.02020406 -0.30964085 -0.42281668]\n [ 0.98019606  1.57197197  0.99784738]\n [ 0.98019606  0.97777845  1.43274454]\n [-1.02020406 -0.30964085 -0.48080297]\n [-1.02020406 -0.11157634  2.15757314]\n [ 0.98019606 -1.49802789 -0.1038921 ]\n [ 0.98019606 -0.11157634  1.95462113]\n [-1.02020406 -0.70576986 -0.33583725]\n [ 0.98019606 -0.50770535 -0.8287207 ]\n [ 0.98019606  0.68068169 -1.37959044]\n [-1.02020406 -0.80480212 -1.58254245]\n [-1.02020406 -1.89415691 -1.46656987]\n [-1.02020406  1.07681071  0.12805305]\n [-1.02020406  0.08648817  1.51972397]\n [-1.02020406 -0.30964085  0.09905991]\n [-1.02020406  0.08648817  0.04107362]\n [-1.02020406 -1.39899564 -1.3505973 ]\n [ 0.98019606  0.28455268  0.07006676]\n [ 0.98019606 -0.90383437  0.38899135]\n [ 0.98019606  1.57197197 -1.26361786]\n [ 0.98019606 -0.30964085 -0.74174127]\n [-1.02020406 -0.11157634  0.1570462 ]\n [ 0.98019606 -0.90383437 -0.65476184]\n [ 0.98019606 -0.70576986 -0.04590581]\n [-1.02020406  0.38358493 -0.45180983]\n [-1.02020406 -0.80480212  1.89663484]\n [ 0.98019606  1.37390747  1.28777882]\n [ 0.98019606  1.17584296 -0.97368642]\n [-1.02020406  1.77003648  1.83864855]\n [-1.02020406 -0.90383437 -0.24885782]\n [-1.02020406 -0.80480212  0.56295021]\n [-1.02020406 -1.20093113 -1.5535493 ]\n [-1.02020406 -0.50770535 -1.11865214]\n [ 0.98019606  0.28455268  0.07006676]\n [-1.02020406 -0.21060859 -1.06066585]\n [ 0.98019606  1.67100423  1.6067034 ]\n [ 0.98019606  0.97777845  1.78066227]\n [ 0.98019606  0.28455268  0.04107362]\n [ 0.98019606 -0.80480212 -0.21986468]\n [-1.02020406 -0.11157634  0.07006676]\n [ 0.98019606  0.28455268 -0.19087153]\n [ 0.98019606  1.96810099 -0.65476184]\n [ 0.98019606 -0.80480212  1.3457651 ]\n [-1.02020406 -1.79512465 -0.59677555]\n [-1.02020406 -0.11157634  0.12805305]\n [-1.02020406  0.28455268 -0.30684411]\n [-1.02020406  1.07681071  0.56295021]\n [-1.02020406 -1.00286662  0.27301877]\n [ 0.98019606  1.47293972  0.35999821]\n [-1.02020406  0.18552042 -0.3648304 ]\n [-1.02020406  2.1661655  -1.03167271]\n [-1.02020406 -0.30964085  1.11381995]\n [-1.02020406 -1.6960924   0.07006676]\n [-1.02020406 -0.01254409  0.04107362]\n [-1.02020406  0.08648817  1.05583366]\n [ 0.98019606 -0.11157634 -0.3648304 ]\n [ 0.98019606 -1.20093113  0.07006676]\n [ 0.98019606 -0.30964085 -1.3505973 ]\n [ 0.98019606  1.57197197  1.11381995]\n [-1.02020406 -0.80480212 -1.52455616]\n [-1.02020406  0.08648817  1.8676417 ]\n [-1.02020406 -0.90383437 -0.77073441]\n [-1.02020406 -0.50770535 -0.77073441]\n [-1.02020406 -0.30964085 -0.91570013]\n [-1.02020406  0.28455268 -0.71274813]\n [ 0.98019606  0.28455268  0.07006676]\n [ 0.98019606  0.08648817  1.8676417 ]\n [ 0.98019606 -1.10189888  1.95462113]\n [ 0.98019606 -1.6960924  -1.5535493 ]\n [-1.02020406 -1.20093113 -1.089659  ]\n [-1.02020406 -0.70576986 -0.1038921 ]\n [ 0.98019606  0.08648817  0.09905991]\n [-1.02020406  0.28455268  0.27301877]\n [ 0.98019606  0.8787462  -0.5677824 ]\n [ 0.98019606  0.28455268 -1.14764529]\n [ 0.98019606 -0.11157634  0.67892279]\n [ 0.98019606  2.1661655  -0.68375498]\n [-1.02020406 -1.29996338 -1.37959044]\n [ 0.98019606 -1.00286662 -0.94469328]\n [ 0.98019606 -0.01254409 -0.42281668]\n [ 0.98019606 -0.21060859 -0.45180983]\n [ 0.98019606 -1.79512465 -0.97368642]\n [ 0.98019606  1.77003648  0.99784738]\n [-1.02020406  0.18552042 -0.3648304 ]\n [ 0.98019606  0.38358493  1.11381995]\n [ 0.98019606 -1.79512465 -1.3505973 ]\n [-1.02020406  0.18552042 -0.13288524]\n [-1.02020406  0.8787462  -1.43757673]\n [ 0.98019606 -1.99318916  0.47597078]\n [-1.02020406 -0.30964085  0.27301877]\n [ 0.98019606  1.86906873 -1.06066585]\n [ 0.98019606 -0.4086731   0.07006676]\n [ 0.98019606  1.07681071 -0.88670699]\n [ 0.98019606 -1.10189888 -1.11865214]\n [-1.02020406 -1.89415691  0.01208048]\n [ 0.98019606  0.08648817  0.27301877]\n [-1.02020406 -1.20093113  0.33100506]\n [-1.02020406 -1.29996338  0.30201192]\n [ 0.98019606 -1.00286662  0.44697764]\n [-1.02020406  1.67100423 -0.88670699]\n [ 0.98019606  1.17584296  0.53395707]\n [-1.02020406  1.07681071  0.53395707]\n [-1.02020406  1.37390747  2.331532  ]\n [ 0.98019606 -0.30964085 -0.13288524]\n [-1.02020406  0.38358493 -0.45180983]\n [-1.02020406 -0.4086731  -0.77073441]\n [-1.02020406 -0.11157634 -0.50979612]\n [ 0.98019606  0.97777845 -1.14764529]\n [-1.02020406 -0.90383437 -0.77073441]\n [-1.02020406 -0.21060859 -0.50979612]\n [ 0.98019606 -1.10189888 -0.45180983]\n [ 0.98019606 -1.20093113  1.40375139]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "JUd6iBRp2C3L",
    "outputId": "a2fd8cf4-37ef-4c38-cece-6f01dd8c83bf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.02020406 -0.80480212  0.50496393]\n [ 0.98019606 -0.01254409 -0.5677824 ]\n [-1.02020406 -0.30964085  0.1570462 ]\n [ 0.98019606 -0.80480212  0.27301877]\n [ 0.98019606 -0.30964085 -0.5677824 ]\n [-1.02020406 -1.10189888 -1.43757673]\n [ 0.98019606 -0.70576986 -1.58254245]\n [-1.02020406 -0.21060859  2.15757314]\n [ 0.98019606 -1.99318916 -0.04590581]\n [-1.02020406  0.8787462  -0.77073441]\n [-1.02020406 -0.80480212 -0.59677555]\n [ 0.98019606 -1.00286662 -0.42281668]\n [-1.02020406 -0.11157634 -0.42281668]\n [-1.02020406  0.08648817  0.21503249]\n [-1.02020406 -1.79512465  0.47597078]\n [ 0.98019606 -0.60673761  1.37475825]\n [-1.02020406 -0.11157634  0.21503249]\n [-1.02020406 -1.89415691  0.44697764]\n [ 0.98019606  1.67100423  1.75166912]\n [-1.02020406 -0.30964085 -1.37959044]\n [ 0.98019606 -0.30964085 -0.65476184]\n [ 0.98019606  0.8787462   2.15757314]\n [ 0.98019606  0.28455268 -0.53878926]\n [-1.02020406  0.8787462   1.02684052]\n [ 0.98019606 -1.49802789 -1.20563157]\n [ 0.98019606  1.07681071  2.07059371]\n [ 0.98019606 -1.00286662  0.50496393]\n [-1.02020406 -0.90383437  0.30201192]\n [ 0.98019606 -0.11157634 -0.21986468]\n [ 0.98019606 -0.60673761  0.47597078]\n [-1.02020406 -1.6960924   0.53395707]\n [-1.02020406 -0.11157634  0.27301877]\n [-1.02020406  1.86906873 -0.27785096]\n [-1.02020406 -0.11157634 -0.48080297]\n [-1.02020406 -1.39899564 -0.33583725]\n [-1.02020406 -1.99318916 -0.50979612]\n [-1.02020406 -1.59706014  0.33100506]\n [ 0.98019606 -0.4086731  -0.77073441]\n [ 0.98019606 -0.70576986 -1.03167271]\n [ 0.98019606  1.07681071 -0.97368642]\n [-1.02020406 -1.10189888  0.53395707]\n [-1.02020406  0.28455268 -0.50979612]\n [ 0.98019606 -1.10189888  0.41798449]\n [-1.02020406 -0.30964085 -1.43757673]\n [ 0.98019606  0.48261718  1.22979253]\n [ 0.98019606 -1.10189888 -0.33583725]\n [ 0.98019606 -0.11157634  0.30201192]\n [ 0.98019606  1.37390747  0.59194336]\n [-1.02020406 -1.20093113 -1.14764529]\n [-1.02020406  1.07681071  0.47597078]\n [ 0.98019606  1.86906873  1.51972397]\n [ 0.98019606 -0.4086731  -1.29261101]\n [ 0.98019606 -0.30964085 -0.3648304 ]\n [-1.02020406 -0.4086731   1.31677196]\n [ 0.98019606  2.06713324  0.53395707]\n [-1.02020406  0.68068169 -1.089659  ]\n [ 0.98019606 -0.90383437  0.38899135]\n [ 0.98019606 -1.20093113  0.30201192]\n [-1.02020406  1.07681071 -1.20563157]\n [-1.02020406 -1.49802789 -1.43757673]\n [-1.02020406 -0.60673761 -1.49556302]\n [-1.02020406  2.1661655  -0.79972756]\n [-1.02020406 -1.89415691  0.18603934]\n [-1.02020406 -0.21060859  0.85288166]\n [ 0.98019606 -1.89415691 -1.26361786]\n [-1.02020406  2.1661655   0.38899135]\n [ 0.98019606 -1.39899564  0.56295021]\n [-1.02020406 -1.10189888 -0.33583725]\n [-1.02020406  0.18552042 -0.65476184]\n [ 0.98019606  0.38358493  0.01208048]\n [ 0.98019606 -0.60673761  2.331532  ]\n [ 0.98019606 -0.30964085  0.21503249]\n [ 0.98019606 -1.59706014 -0.19087153]\n [-1.02020406  0.68068169 -1.37959044]\n [-1.02020406 -1.10189888  0.56295021]\n [-1.02020406 -1.99318916  0.35999821]\n [ 0.98019606  0.38358493  0.27301877]\n [ 0.98019606  0.18552042 -0.27785096]\n [ 0.98019606  1.47293972 -1.03167271]\n [ 0.98019606  0.8787462   1.08482681]\n [-1.02020406  1.96810099  2.15757314]\n [ 0.98019606  2.06713324  0.38899135]\n [ 0.98019606 -1.39899564 -0.42281668]\n [ 0.98019606 -1.20093113 -1.00267957]\n [ 0.98019606  1.96810099 -0.91570013]\n [ 0.98019606  0.38358493  0.30201192]\n [ 0.98019606  0.18552042  0.1570462 ]\n [-1.02020406  2.06713324  1.75166912]\n [ 0.98019606  0.77971394 -0.8287207 ]\n [ 0.98019606  0.28455268 -0.27785096]\n [-1.02020406  0.38358493 -0.16187839]\n [ 0.98019606 -0.11157634  2.21555943]\n [ 0.98019606 -1.49802789 -0.62576869]\n [-1.02020406 -1.29996338 -1.06066585]\n [-1.02020406 -1.39899564  0.41798449]\n [ 0.98019606 -1.10189888  0.76590222]\n [-1.02020406 -1.49802789 -0.19087153]\n [-1.02020406  0.97777845 -1.06066585]\n [-1.02020406  0.97777845  0.59194336]\n [-1.02020406  0.38358493  0.99784738]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "**Training Model on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "e0pFVAmciHQs",
    "outputId": "657a7cbd-de85-47f8-9b7f-51e9f5676c2a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "#fitting the regression model to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKYVQH-l5NpE"
   },
   "source": [
    "**Predicting the Test set results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "p6VMTb2O4hwM",
    "outputId": "abf60dd9-afb3-4304-ace2-6b8d28307db0"
   },
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.2208572   0.29071286  0.30769543  0.18972007  0.21072947 -0.11856922\n -0.03144498  0.60154415 -0.17280858  0.50371587  0.0737104   0.043463\n  0.283572    0.4220845  -0.04962637  0.39018912  0.36876225 -0.08015978\n  1.05373475  0.10246437  0.19911262  0.89465771  0.37456853  0.74379748\n -0.19439431  0.93636311  0.16737609  0.16709008  0.31051914  0.27014832\n -0.01522067  0.37650682  0.83615597  0.27582743 -0.05140581 -0.23460628\n -0.01566553  0.15696236  0.04212842  0.52977329  0.1447461   0.37859966\n  0.12909811  0.0947198   0.66410011  0.02841873  0.38022025  0.81886001\n -0.10650751  0.72354634  1.07607874  0.08726125  0.23783546  0.43592566\n  0.99774334  0.40779849  0.17854808  0.08694785  0.49895386 -0.22521373\n  0.00699185  0.84643824 -0.11501033  0.42729137 -0.30878339  1.00520189\n  0.06847615  0.02857757  0.33257711  0.47480305  0.5179745   0.31528114\n -0.08552549  0.36907565  0.14861838 -0.11843776  0.50965361  0.38275795\n  0.62867323  0.7513832   1.18808896  0.97838191 -0.06318151 -0.08730494\n  0.777468    0.51352589  0.44084222  1.16053811  0.46915132  0.40941908\n  0.4517282   0.635791   -0.11694863 -0.12155178  0.04927358  0.17556552\n -0.05870552  0.49165416  0.71237435  0.60661956]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.0537347548661782, 0.8946577099041704, 0.936363113177525, 0.8361559748993282, 0.8188600090322462, 1.076078737811005, 0.9977433350474856, 0.8464382449223347, 1.0052018916162648, 0.7513831994730626, 1.1880889641538357, 0.9783819147189576, 0.777468004026969, 1.160538114969193, 1.0537347548661782, 0.8946577099041704, 0.936363113177525, 0.8361559748993282, 0.8188600090322462, 1.076078737811005, 0.9977433350474856, 0.8464382449223347, 1.0052018916162648, 0.7513831994730626, 1.1880889641538357, 0.9783819147189576, 0.777468004026969, 1.160538114969193, 1.0537347548661782, 0.8946577099041704, 0.936363113177525, 0.8361559748993282, 0.8188600090322462, 1.076078737811005, 0.9977433350474856, 0.8464382449223347, 1.0052018916162648, 0.7513831994730626, 1.1880889641538357, 0.9783819147189576, 0.777468004026969, 1.160538114969193]\n28 100\n"
     ]
    }
   ],
   "source": [
    "nr0 = 0\n",
    "nr1=0\n",
    "purchase0=[]\n",
    "purchase1=[]\n",
    "for i in y_pred:\n",
    "    if i>0.75:\n",
    "        nr1=nr1+1\n",
    "        purchase1.append(i)\n",
    "        dataset['o/p']=1\n",
    "    else:\n",
    "        nr0=nr0+1\n",
    "        purchase0.append(i)\n",
    "        dataset['o/p']=0\n",
    "print(purchase)\n",
    "print(nr,len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset['o/p']:\n",
    "    if(i==1):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased  o/p\n",
       "0  15624510       0   19            19000          0    0\n",
       "1  15810944       0   35            20000          0    0\n",
       "2  15668575       1   26            43000          0    0\n",
       "3  15603246       1   27            57000          0    0\n",
       "4  15804002       0   19            76000          0    0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>EstimatedSalary</th>\n      <th>Purchased</th>\n      <th>o/p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15624510</td>\n      <td>0</td>\n      <td>19</td>\n      <td>19000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15810944</td>\n      <td>0</td>\n      <td>35</td>\n      <td>20000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15668575</td>\n      <td>1</td>\n      <td>26</td>\n      <td>43000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15603246</td>\n      <td>1</td>\n      <td>27</td>\n      <td>57000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15804002</td>\n      <td>0</td>\n      <td>19</td>\n      <td>76000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ab3fa311064e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4Hwj34ziWQW"
   },
   "source": [
    "**Confusion Matrix and Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "D6bpZwUiiXic",
    "outputId": "cf81b9bd-784e-4e66-b9db-85e54dfd742d"
   },
   "outputs": [],
   "source": [
    "# #visualising the results of the training set\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(X_train,y_train,color=\"red\")\n",
    "# plt.plot(X_train,regressor.predict(X_train),color=\"blue\")\n",
    "# plt.title(\"Linear Regression Model For Training Set\")\n",
    "# plt.xlabel(\"Years of Experience\")\n",
    "# plt.ylabel(\"Salary\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualising the results of the test set\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(X_test,y_test,color=\"red\")\n",
    "# # we observe that the test line and the train line are coincident ,\n",
    "# # that is simply because we have used the same linear regression model\n",
    "# plt.plot(X_train,regressor.predict(X_train),color=\"blue\")\n",
    "# plt.plot(X_test,y_pred,color=\"green\")\n",
    "# plt.title(\"Linear Regression Model For Test Set\")\n",
    "# plt.xlabel(\"Years of Experience\")\n",
    "# plt.ylabel(\"Salary\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of logistic_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python36964bit55d55954de964b92a821f9dd68bb8a06",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}